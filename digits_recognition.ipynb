{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digits recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/sebastianoscarlopez/learning-deep-learning/blob/master/digits_recognition.ipynb",
      "authorship_tag": "ABX9TyN/YotqNuJbanNarMxOy7YQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianoscarlopez/learning-deep-learning/blob/master/digits_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HP-Dh_6ZckV",
        "colab_type": "text"
      },
      "source": [
        "# Description\n",
        "\n",
        "Digits recognition it is called the Hello World of Neural Network.\n",
        "\n",
        "Made using Python, numpy applied to MNIST dataset.\n",
        "\n",
        "It example is based on http://neuralnetworksanddeeplearning.com/chap1.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wf2jrkItPrkd"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjWQpXIVQAHM",
        "colab_type": "text"
      },
      "source": [
        "## Base libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6rkxiBZA_Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBBnR-Fop9OL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac7019cf-ef8d-406d-aaea-1e47e0a9f3ee"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3-sDpO9PtIS",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC_M5N7_QNN1",
        "colab_type": "text"
      },
      "source": [
        "**mnist_loader**\n",
        "\n",
        "A library to load the MNIST image $28*28$ with digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc7UHuIB0EX-",
        "colab_type": "text"
      },
      "source": [
        "data stored on training_data (60%) test_data (10%), array image rearrange in vector of 784"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiQm4nv81nr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30VBYRYPZhAc",
        "colab_type": "text"
      },
      "source": [
        "unit vector with a 1.0 in the jth position and zeroes elsewhere.\n",
        "\n",
        "Output layer are 10 neurons representing numbers from 0 to 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIA70eakY4oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorized_result(j):\n",
        "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
        "    position and zeroes elsewhere.  This is used to convert a digit\n",
        "    (0...9) into a corresponding desired output from the neural\n",
        "    network.\"\"\"\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWfkDgb7A0fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "training_inputs = [ np.reshape(x, (784, 1)) for x in x_train ]\n",
        "training_results = [ vectorized_result(y) for y in y_train ]\n",
        "training_data = list(zip(training_inputs, training_results))#list(map(lambda x, y: [x, y], training_inputs, training_results))\n",
        "test_inputs = [ np.reshape(x, (784, 1)) for x in x_test ]\n",
        "test_data = list(zip(test_inputs, y_test)) #list(map(lambda x, y: [x, y], test_inputs, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rl7Ib6hrPWy",
        "colab_type": "text"
      },
      "source": [
        "# Network design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZIlym0zrtBr",
        "colab_type": "text"
      },
      "source": [
        "Class wich made the network. The **sizes** parameter in its constructors is an array with the number of neurons on each layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSOB8zQrThg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(object):\n",
        "  def __init__(self, sizes):\n",
        "      self.num_layers = len(sizes)\n",
        "      self.sizes = sizes\n",
        "      self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "      self.weights = [np.random.randn(y, x) \n",
        "                      for x, y in zip(sizes[:-1], sizes[1:])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7blpLN3yy5nr",
        "colab_type": "text"
      },
      "source": [
        "Trainning using Stochastic Gradient Descent.\n",
        "    \n",
        "training_data\" is a list of tuples \"(x, y)\" representing the training inputs and the desired outputs.\n",
        "\n",
        "epochs total of trainning.\n",
        "\n",
        "mini_batch_size indicated the group of data to be trainning together\n",
        "\n",
        "eta is the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGyngxxJyEfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def SGD(self, training_data, epochs, mini_batch_size, eta, progress_callback = None):\n",
        "    n = len(training_data)\n",
        "    for j in range(epochs):\n",
        "        np.random.shuffle(training_data)\n",
        "        progress_callback(j, False)\n",
        "        mini_batches = [\n",
        "            training_data[k:k+mini_batch_size]\n",
        "            for k in range(0, n, mini_batch_size)]\n",
        "        for mini_batch in mini_batches:\n",
        "            self.update_mini_batch(mini_batch, eta)\n",
        "        if progress_callback:\n",
        "          progress_callback(j, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLdL8ptkvE8b",
        "colab_type": "text"
      },
      "source": [
        "Given the input $x$ returns the output vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXUIKWDWvHIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def feedforward(self, x):\n",
        "    for b, w in zip(self.biases, self.weights):\n",
        "        x = self.sigmoid(np.dot(w, x)+b)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QBcS9JbaFHB",
        "colab_type": "text"
      },
      "source": [
        "Update the network's weights and biases by applying gradient descent using backpropagation to a single mini batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYqkuUl0Z6fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def update_mini_batch(self, mini_batch, eta):\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "    for x, y in mini_batch:\n",
        "        delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "    self.weights = [w-(eta/len(mini_batch))*nw \n",
        "                    for w, nw in zip(self.weights, nabla_w)]\n",
        "    self.biases = [b-(eta/len(mini_batch))*nb \n",
        "                    for b, nb in zip(self.biases, nabla_b)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_utRp-Vk5Fo",
        "colab_type": "text"
      },
      "source": [
        "Return a tuple $\\nabla a, \\nabla b$ representing the gradient for the cost function $C_x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sqqoMfbXfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "    def backprop(self, x, y):\n",
        "      nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "      nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "      # feedforward\n",
        "      activation = x\n",
        "      activations = [x] # list to store all the activations, layer by layer\n",
        "      zs = [] # list to store all the z vectors, layer by layer\n",
        "      for b, w in zip(self.biases, self.weights):\n",
        "          z = np.dot(w, activation)+b\n",
        "          zs.append(z)\n",
        "          activation = self.sigmoid(z)\n",
        "          activations.append(activation)\n",
        "      # backward pass\n",
        "      delta = self.cost_derivative(activations[-1], y) * \\\n",
        "          self.sigmoid_prime(zs[-1])\n",
        "      nabla_b[-1] = delta\n",
        "      nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "      # Note that the variable l in the loop below is used a little\n",
        "      # differently to the notation in Chapter 2 of the book.  Here,\n",
        "      # l = 1 means the last layer of neurons, l = 2 is the\n",
        "      # second-last layer, and so on.  It's a renumbering of the\n",
        "      # scheme in the book, used here to take advantage of the fact\n",
        "      # that Python can use negative indices in lists.\n",
        "      for l in range(2, self.num_layers):\n",
        "          z = zs[-l]\n",
        "          sp = self.sigmoid_prime(z)\n",
        "          delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "          nabla_b[-l] = delta\n",
        "          nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "      return (nabla_b, nabla_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aFCD3wUmm3m",
        "colab_type": "text"
      },
      "source": [
        "Return the number of test inputs for which the neural network outputs the correct result.\n",
        "\n",
        "The output will to be the neuron in the final layer that has the highest activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIrLzk5Qm_o7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def evaluate(self, test_data):\n",
        "    test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                    for (x, y) in test_data]\n",
        "    return sum(int(x == y) for (x, y) in test_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL7f07tHnpPr",
        "colab_type": "text"
      },
      "source": [
        "Return the vector of partial derivatives $\\partial C_x \\partial a$ for the output activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn6JLdDinrsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def cost_derivative(self, output_activations, y):\n",
        "    return (output_activations-y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyP-PRcCshgu",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid neuron $\\sigma(\\zeta) = \\frac{1}{1 + e^{-\\zeta}}$ where $-\\zeta = w.x + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-sm7xB8sCyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def sigmoid(self, z):\n",
        "    return 1.0/(1.0+np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9DswPMXoryg",
        "colab_type": "text"
      },
      "source": [
        "$f'(\\sigma)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMGBhiecok9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(Network):\n",
        "  def sigmoid_prime(self, z):\n",
        "    return self.sigmoid(z)*(1-self.sigmoid(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2yjgo3Ap6_d",
        "colab_type": "text"
      },
      "source": [
        "# Network creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4tylZ4Urqjv",
        "colab_type": "text"
      },
      "source": [
        "Network with 3 layers\n",
        "input layer: $784 = 28 * 28$\n",
        "\n",
        "Hidden layer: only one with 30 neurons\n",
        "\n",
        "Output layer: 10 neurons representing 0-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLxkisa-p6Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Network([784, 30, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxmhH3gsppJC",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnWEKRoN5SQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_folder = '/content/gdrive/My Drive/Colab'\n",
        "model_name = 'digits_recognition.model'\n",
        "path_model = f'{path_folder}/{model_name}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7UKiPVeDduO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model():\n",
        "  model_stream = open(path,\"wb\")\n",
        "  current_model = [net.weights, net.biases]\n",
        "  pickle.dump(current_model, model_stream)\n",
        "  model_stream.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_saeoquR0FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model():\n",
        "  print(path_model)\n",
        "  model_stream = open(path_model,\"rb\")\n",
        "  current_model = pickle.load(model_stream)\n",
        "  model_stream.close()\n",
        "  net.weights = current_model[0]\n",
        "  net.biases = current_model[1]\n",
        "  net.num_layers = len(net.weights) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6q1DaxZn5XP",
        "colab_type": "text"
      },
      "source": [
        "The network will be evaluated against the test data after each epoch. This is useful for tracking progress, but slows things down substantially.\n",
        "It will save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScW01T-dmqFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def progress_callback(epoch, is_complete):\n",
        "  save_model()\n",
        "  if epoch == 0 and not is_complete:\n",
        "    print(\".Start {0} / {1}\".format(net.evaluate(test_data), len(test_data)))\n",
        "  if is_complete:\n",
        "    print(\"Epoch {0}: {1} / {2}\".format(epoch, net.evaluate(test_data), len(test_data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaiJOBmnqsis",
        "colab_type": "text"
      },
      "source": [
        "Load previous model saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Dg0htKqn6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e079596-5e3b-4a2c-85f6-263cfa8f5c93"
      },
      "source": [
        "if os.path.exists(path_model):\n",
        "  load_model()"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab/digits_recognition.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubezplagpxNE",
        "colab_type": "code",
        "outputId": "9f6f38e7-5bb7-40b8-c0e4-f3eee54e8b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "net.SGD(training_data, 200, 100, 0.1, progress_callback)"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".Start 8770 / 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-322-805b3ad66cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-308-616e6b41b97f>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, progress_callback)\u001b[0m\n\u001b[1;32m      9\u001b[0m             for k in range(0, n, mini_batch_size)]\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogress_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mprogress_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-310-a8ccf8286771>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, mini_batch, eta)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnabla_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdnb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdnw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabla_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-311-4c2694086ade>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# list to store all the z vectors, layer by layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           \u001b[0mzs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2lAcUShGx-P",
        "colab_type": "text"
      },
      "source": [
        "A custom 5 digit for validate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W95pwAEDNLqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_data[0][0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eukAImeA6rOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "d56cf81f-8383-49b2-dbd6-c11ce33856cb"
      },
      "source": [
        "def validationData():\n",
        "  image_name = '5_2.bmp'\n",
        "  path_image = f'{path_folder}/{image_name}'\n",
        "  image_stream = open(path_image,\"rb\")\n",
        "  ba = bytearray(image_stream.read())\n",
        "  pixels = np.flip(np.array(ba[len(ba)-784:]).reshape((28, 28)), 0)\n",
        "  plt.imshow(pixels, cmap='gray')\n",
        "  x = pixels.reshape((784,1))\n",
        "  result = net.sigmoid(np.dot(net.weights[0], x) + net.biases[0])\n",
        "  result = net.sigmoid(np.dot(net.weights[1], result) + net.biases[1])\n",
        "  result = np.argmax(result)\n",
        "  print(result)\n",
        "\n",
        "  plt.show()\n",
        "validationData()"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZyYZDGP1BZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw(input, label, output):\n",
        "  image = np.reshape(input, (28, 28))\n",
        "  image = np.array(image, dtype='float')\n",
        "  pixels = image.reshape((28, 28))\n",
        "  plt.imshow(pixels, cmap='gray')\n",
        "  plt.show()\n",
        "  print(\"{0} - {1}\".format(label, output))\n",
        "\n",
        "        draw(test_data[0][0], test_data[0][1], self.evaluate(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}