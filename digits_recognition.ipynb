{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digits recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdP4WJcqGIJzon9DHd+Fov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianoscarlopez/learning-deep-learning/blob/master/digits_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HP-Dh_6ZckV",
        "colab_type": "text"
      },
      "source": [
        "# Description\n",
        "\n",
        "Digits recognition it is called the Hello World of Neural Network.\n",
        "\n",
        "Made using Python, numpy applied to MNIST dataset.\n",
        "\n",
        "It example is based on http://neuralnetworksanddeeplearning.com/chap1.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wf2jrkItPrkd"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjWQpXIVQAHM",
        "colab_type": "text"
      },
      "source": [
        "## Base libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBBnR-Fop9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3-sDpO9PtIS",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lME56oHNPlZ2",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston as load_boston\n",
        "boston = load_boston()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC_M5N7_QNN1",
        "colab_type": "text"
      },
      "source": [
        "Description about data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rl7Ib6hrPWy",
        "colab_type": "text"
      },
      "source": [
        "# Network design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZIlym0zrtBr",
        "colab_type": "text"
      },
      "source": [
        "Class wich made the network. The **sizes** parameter in its constructors is an array with the number of neurons on each layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSOB8zQrThg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(object):\n",
        "  def __init__(self, sizes):\n",
        "      self.num_layers = len(sizes)\n",
        "      self.sizes = sizes\n",
        "      self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "      self.weights = [np.random.randn(y, x) \n",
        "                      for x, y in zip(sizes[:-1], sizes[1:])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyP-PRcCshgu",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid neuron $\\sigma(\\zeta) = \\frac{1}{1 + e^{-\\zeta}}$ where $-\\zeta = w.x + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-sm7xB8sCyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def sigmoid(z):\n",
        "    return 1.0/(1.0+np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLdL8ptkvE8b",
        "colab_type": "text"
      },
      "source": [
        "Given the input $x$ returns the output vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXUIKWDWvHIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def feedforward(self, x):\n",
        "    for b, w in zip(self.biases, self.weights):\n",
        "        x = sigmoid(np.dot(w, x)+b)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7blpLN3yy5nr",
        "colab_type": "text"
      },
      "source": [
        "Trainning using Stochastic Gradient Descent.\n",
        "    \n",
        "training_data\" is a list of tuples \"(x, y)\" representing the training inputs and the desired outputs.\n",
        "\n",
        "epochs total of trainning.\n",
        "\n",
        "mini_batch_size indicated the group of data to be trainning together\n",
        "\n",
        "eta step size\n",
        "\n",
        "test_data is provided then the network will be evaluated against the test data after each epoch, and partial progress printed out.  This is useful for tracking progress, but slows things down substantially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGyngxxJyEfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
        "    if test_data: n_test = len(test_data)\n",
        "    n = len(training_data)\n",
        "    for j in xrange(epochs):\n",
        "        random.shuffle(training_data)\n",
        "        mini_batches = [\n",
        "            training_data[k:k+mini_batch_size]\n",
        "            for k in xrange(0, n, mini_batch_size)]\n",
        "        for mini_batch in mini_batches:\n",
        "            self.update_mini_batch(mini_batch, eta)\n",
        "        if test_data:\n",
        "            print \"Epoch {0}: {1} / {2}\".format(\n",
        "                j, self.evaluate(test_data), n_test)\n",
        "        else:\n",
        "            print \"Epoch {0} complete\".format(j)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}